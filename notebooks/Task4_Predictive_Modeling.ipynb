{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f56398",
   "metadata": {},
   "source": [
    "## Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a41d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Task 4: Predictive Modeling Environment Ready\n",
      "Libraries loaded: pandas, sklearn, xgboost, shap\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix,  accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "# Models we'll use\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# For model interpretation\n",
    "import shap\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Task 4: Predictive Modeling Environment Ready\")\n",
    "print(\"Libraries loaded: pandas, sklearn, xgboost, shap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477a338",
   "metadata": {},
   "source": [
    "## Loading the data and understainding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abdab1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading SAMPLE data (100K rows) for model development...\n",
      "‚úÖ Sample loaded: 100,000 rows √ó 57 columns\n",
      "   This is 10% of full dataset\n",
      "   Note: We'll use full dataset for final model\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 Modified: Load SAMPLE data\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_path = Path(\"../data/processed/insurance_data_cleaned.csv\")\n",
    "\n",
    "# Load only first 100,000 rows for development\n",
    "print(\"üìä Loading SAMPLE data (100K rows) for model development...\")\n",
    "df = pd.read_csv(data_path, nrows=100000)  # LIMIT rows for testing\n",
    "\n",
    "print(f\"‚úÖ Sample loaded: {len(df):,} rows √ó {len(df.columns)} columns\")\n",
    "print(f\"   This is 10% of full dataset\")\n",
    "print(\"   Note: We'll use full dataset for final model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dab576",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4bf200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: FEATURE SELECTION BASED ON EDA & HYPOTHESIS TESTING\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 4: FEATURE SELECTION FOR PREDICTIVE MODELING\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nBased on Task 1 (EDA) and Task 3 (Hypothesis Testing):\")\n",
    "print(\"1. Province ‚Üí STATISTICALLY SIGNIFICANT risk differences\")\n",
    "print(\"2. Zip Code ‚Üí EXTREMELY SIGNIFICANT risk differences\")  \n",
    "print(\"3. Vehicle Type ‚Üí Important from EDA\")\n",
    "print(\"4. Registration Year ‚Üí Age of vehicle affects risk\")\n",
    "print(\"5. Gender ‚Üí NOT statistically significant (but include for completeness)\")\n",
    "\n",
    "# Select features for modeling\n",
    "print(\"\\nüìã SELECTING FEATURES:\")\n",
    "\n",
    "# Categorical features (from our analysis)\n",
    "categorical_features = [\n",
    "    'Province',           # ‚úÖ Proven significant (Hypothesis 1)\n",
    "    'VehicleType',        # ‚úÖ Important from EDA\n",
    "    'Gender',             # ‚ö†Ô∏è Not significant but include\n",
    "    'CoverType',          # ‚ö†Ô∏è Business logic - different coverage\n",
    "    'make'                # ‚úÖ Vehicle make from EDA\n",
    "]\n",
    "\n",
    "# Numerical features\n",
    "numerical_features = [\n",
    "    'RegistrationYear',   # ‚úÖ Vehicle age matters\n",
    "    'cubiccapacity',      # ‚úÖ Engine size from EDA\n",
    "    'SumInsured',         # ‚úÖ Coverage amount affects risk\n",
    "    'ExcessSelected'      # ‚úÖ Deductible affects behavior\n",
    "]\n",
    "\n",
    "# Target variables (we'll decide which to use)\n",
    "potential_targets = ['TotalClaims', 'AnnualPremium']\n",
    "\n",
    "print(f\"\\nüéØ SELECTED {len(categorical_features)} CATEGORICAL FEATURES:\")\n",
    "for feat in categorical_features:\n",
    "    if feat in df.columns:\n",
    "        print(f\"   ‚úì {feat} ({df[feat].nunique()} unique values)\")\n",
    "    else:\n",
    "        print(f\"   ‚úó {feat} (MISSING from dataset)\")\n",
    "\n",
    "print(f\"\\nüìä SELECTED {len(numerical_features)} NUMERICAL FEATURES:\")\n",
    "for feat in numerical_features:\n",
    "    if feat in df.columns:\n",
    "        # Check if the column is numeric\n",
    "        if pd.api.types.is_numeric_dtype(df[feat]):\n",
    "            # For numeric columns, show range with 2 decimal places\n",
    "            print(f\"‚úì {feat} (range: {df[feat].min():.2f} to {df[feat].max():.2f})\")\n",
    "        else:\n",
    "            # For non-numeric columns, just show min and max as strings\n",
    "            print(f\"‚úì {feat} (range: '{df[feat].min()}' to '{df[feat].max()}')\")\n",
    "    else:\n",
    "        print(f\"‚úó {feat} (MISSING from dataset)\")\n",
    "\n",
    "print(f\"\\nüéØ POTENTIAL TARGET VARIABLES:\")\n",
    "for target in potential_targets:\n",
    "    if target in df.columns:\n",
    "        print(f\"   ‚úì {target}\")\n",
    "    else:\n",
    "        print(f\"   ‚úó {target} (MISSING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8683d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: DATA QUALITY CHECK FOR SELECTED FEATURES\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: DATA QUALITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Filter to features that actually exist in our data\n",
    "available_categorical = [f for f in categorical_features if f in df.columns]\n",
    "available_numerical = [f for f in numerical_features if f in df.columns]\n",
    "\n",
    "print(f\"\\nüìä AVAILABLE FEATURES IN OUR SAMPLE:\")\n",
    "print(f\"   Categorical: {len(available_categorical)}/{len(categorical_features)}\")\n",
    "print(f\"   Numerical: {len(available_numerical)}/{len(numerical_features)}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nüîç MISSING VALUES CHECK:\")\n",
    "missing_summary = {}\n",
    "for feature in available_categorical + available_numerical:\n",
    "    missing_count = df[feature].isnull().sum()\n",
    "    missing_pct = (missing_count / len(df)) * 100\n",
    "    if missing_count > 0:\n",
    "        missing_summary[feature] = missing_pct\n",
    "        print(f\"   ‚ö†Ô∏è {feature}: {missing_count:,} missing ({missing_pct:.1f}%)\")\n",
    "\n",
    "if not missing_summary:\n",
    "    print(\"   ‚úÖ No missing values in selected features!\")\n",
    "\n",
    "# Check target variable\n",
    "print(\"\\nüéØ TARGET VARIABLE ANALYSIS:\")\n",
    "if 'TotalClaims' in df.columns:\n",
    "    print(f\"   TotalClaims range: R{df['TotalClaims'].min():,.2f} to R{df['TotalClaims'].max():,.2f}\")\n",
    "    # FIXED: Removed extra parentheses\n",
    "    print(f\"   Policies with claims: {(df['TotalClaims'] > 0).sum():,} ({(df['TotalClaims'] > 0).mean()*100:.2f}%)\")\n",
    "    print(f\"   Average claim: R{df[df['TotalClaims'] > 0]['TotalClaims'].mean():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: DECISION POINT - MODELING STRATEGY\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: CHOOSE MODELING APPROACH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nü§î BUSINESS QUESTION:\")\n",
    "print(\"What does ACIS need most for pricing optimization?\")\n",
    "\n",
    "print(\"\\nüìä OPTION 1: CLAIM SEVERITY MODEL\")\n",
    "print(\"   ‚Ä¢ Predict: TotalClaims amount (when claims occur)\")\n",
    "print(\"   ‚Ä¢ Type: Regression\")\n",
    "print(\"   ‚Ä¢ Data: Only policies with claims (~0.28% of data)\")\n",
    "print(\"   ‚Ä¢ Use: Estimating financial liability\")\n",
    "print(\"   ‚Ä¢ Pros: Direct business impact\")\n",
    "print(\"   ‚Ä¢ Cons: Very few samples for training\")\n",
    "\n",
    "print(\"\\nüìä OPTION 2: CLAIM PROBABILITY MODEL\")\n",
    "print(\"   ‚Ä¢ Predict: TotalClaims (will a claim occur?)\")\n",
    "print(\"   ‚Ä¢ Type: Classification\")\n",
    "print(\"   ‚Ä¢ Data: ALL policies\")\n",
    "print(\"   ‚Ä¢ Use: Risk assessment for underwriting\")\n",
    "print(\"   ‚Ä¢ Pros: More data, useful for screening\")\n",
    "print(\"   ‚Ä¢ Cons: Doesn't predict amount\")\n",
    "\n",
    "print(\"\\nüìä OPTION 3: TWO-STAGE MODEL (RECOMMENDED)\")\n",
    "print(\"   ‚Ä¢ Stage 1: Predict TotalClaims (classification)\")\n",
    "print(\"   ‚Ä¢ Stage 2: Predict TotalClaims (regression, claims only)\")\n",
    "print(\"   ‚Ä¢ Combined: Expected Loss = Probability √ó Amount\")\n",
    "print(\"   ‚Ä¢ Use: Complete risk assessment\")\n",
    "print(\"   ‚Ä¢ Pros: Comprehensive, business-relevant\")\n",
    "print(\"   ‚Ä¢ Cons: More complex\")\n",
    "\n",
    "print(\"\\nüìä OPTION 4: PREMIUM PREDICTION MODEL\")\n",
    "print(\"   ‚Ä¢ Predict: AnnualPremium directly\")\n",
    "print(\"   ‚Ä¢ Type: Regression\")\n",
    "print(\"   ‚Ä¢ Data: ALL policies\")\n",
    "print(\"   ‚Ä¢ Use: Benchmark current pricing\")\n",
    "print(\"   ‚Ä¢ Pros: Simple, direct\")\n",
    "print(\"   ‚Ä¢ Cons: May just replicate existing biases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CREATE TARGET VARIABLES FOR TWO-STAGE MODELING\n",
    "print(\"üéØ CREATING TARGET VARIABLES FOR TWO-STAGE MODELING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create binary target: TotalClaims (1 if TotalClaims > 0, else 0)\n",
    "df['TotalClaims'] = (df['TotalClaims'] > 0).astype(int)\n",
    "\n",
    "print(f\"\\nüìä CLAIM DISTRIBUTION:\")\n",
    "print(f\"   ‚Ä¢ Policies with NO claims: {(df['TotalClaims'] == 0).sum():,} ({(df['TotalClaims'] == 0).mean()*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Policies WITH claims: {(df['TotalClaims'] == 1).sum():,} ({(df['TotalClaims'] == 1).mean()*100:.2f}%)\")\n",
    "\n",
    "# Create subset for regression (only policies with claims)\n",
    "df_claims = df[df['TotalClaims'] == 1].copy()\n",
    "print(f\"\\nüìà REGRESSION SUBSET (claims only): {len(df_claims):,} rows\")\n",
    "\n",
    "print(f\"\\nüí∞ CLAIM AMOUNT STATISTICS (for regression target):\")\n",
    "print(f\"   ‚Ä¢ Minimum claim: R {df_claims['TotalClaims'].min():,.2f}\")\n",
    "print(f\"   ‚Ä¢ Maximum claim: R {df_claims['TotalClaims'].max():,.2f}\")\n",
    "print(f\"   ‚Ä¢ Average claim: R {df_claims['TotalClaims'].mean():,.2f}\")\n",
    "print(f\"   ‚Ä¢ Median claim: R {df_claims['TotalClaims'].median():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b904e",
   "metadata": {},
   "source": [
    "# Based on the project requirements and business needs, I recommend:\n",
    "\n",
    "Two-Stage Model because:\n",
    "\n",
    "- Meets requirements: \"Build a machine learning model that predicts optimal premium values\"\n",
    "\n",
    "- Business logic: Premium should reflect both claim probability AND amount\n",
    "\n",
    "- Regulatory: More transparent (can explain both components)\n",
    "\n",
    "- Practical: We already have TotalClaims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7332ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FINAL FEATURE SELECTION FOR MODELING\n",
    "print(\"üîç FINAL FEATURE SELECTION FOR PREDICTIVE MODELING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Based on your EDA (Task 1) and Hypothesis Testing (Task 3)\n",
    "selected_features = {\n",
    "    'location': ['Province', 'PostalCode', 'MainCrestaZone'],  # SIGNIFICANT from Task 3\n",
    "    'vehicle': ['VehicleType', 'make', 'RegistrationYear', 'cubiccapacity', 'Bodytype'],\n",
    "    'client': ['Gender', 'MaritalStatus', 'Bank', 'AccountType'],  # Gender NOT significant but include\n",
    "    'plan': ['CoverType', 'SumInsured', 'ExcessSelected', 'TermFrequency']\n",
    "}\n",
    "\n",
    "# Flatten the list\n",
    "all_features = []\n",
    "for category, features in selected_features.items():\n",
    "    for feature in features:\n",
    "        if feature in df.columns:\n",
    "            all_features.append(feature)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: {feature} not in dataset\")\n",
    "\n",
    "print(f\"\\n‚úÖ SELECTED {len(all_features)} FEATURES:\")\n",
    "print(f\"   ‚Ä¢ Location features: {[f for f in selected_features['location'] if f in df.columns]}\")\n",
    "print(f\"   ‚Ä¢ Vehicle features: {[f for f in selected_features['vehicle'] if f in df.columns]}\")\n",
    "print(f\"   ‚Ä¢ Client features: {[f for f in selected_features['client'] if f in df.columns]}\")\n",
    "print(f\"   ‚Ä¢ Plan features: {[f for f in selected_features['plan'] if f in df.columns]}\")\n",
    "\n",
    "# Categorical vs Numerical split\n",
    "categorical_features = []\n",
    "numerical_features = []\n",
    "\n",
    "for feature in all_features:\n",
    "    if df[feature].dtype == 'object' or df[feature].nunique() < 10:\n",
    "        categorical_features.append(feature)\n",
    "    else:\n",
    "        numerical_features.append(feature)\n",
    "\n",
    "print(f\"\\nüìä FEATURE TYPES:\")\n",
    "print(f\"   ‚Ä¢ Categorical: {len(categorical_features)} features\")\n",
    "print(f\"   ‚Ä¢ Numerical: {len(numerical_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b151338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: CREATE PREPROCESSING PIPELINE\n",
    "print(\"üîÑ CREATING DATA PREPROCESSING PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Separate features and targets\n",
    "X = df[all_features].copy()\n",
    "y_classification = df['TotalClaims']  # For classification model\n",
    "y_regression = df_claims['TotalClaims']  # For regression model (subset)\n",
    "X_regression = df_claims[all_features].copy()  # Features for regression model\n",
    "\n",
    "print(f\"\\nüìê DATA SHAPES:\")\n",
    "print(f\"   ‚Ä¢ Full dataset for classification: {X.shape}\")\n",
    "print(f\"   ‚Ä¢ Claims subset for regression: {X_regression.shape}\")\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "print(\"\\n‚öôÔ∏è BUILDING PREPROCESSING TRANSFORMER...\")\n",
    "\n",
    "# Numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n",
    "    ('scaler', StandardScaler())  # Standardize features\n",
    "])\n",
    "\n",
    "# Categorical pipeline  \n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill with mode\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine both pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Preprocessing pipeline created successfully!\")\n",
    "print(f\"   ‚Ä¢ Will process {len(numerical_features)} numerical features\")\n",
    "print(f\"   ‚Ä¢ Will process {len(categorical_features)} categorical features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c783d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TRAIN-TEST SPLIT WITH 500K SAMPLES\n",
    "print(\"üìä CREATING TRAIN-TEST SPLITS (100K Samples)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Now have {len(X_regression):,} claims - much better for modeling!\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split for CLASSIFICATION model\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_classification, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_classification\n",
    ")\n",
    "\n",
    "# For REGRESSION: Now we have enough data for proper split\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_regression, y_regression,\n",
    "    test_size=0.2,  # Can use 20% now\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nüî¢ CLASSIFICATION DATA SPLIT (500K samples):\")\n",
    "print(f\"   ‚Ä¢ Training: {X_train_clf.shape[0]:,} samples\")\n",
    "print(f\"   ‚Ä¢ Testing: {X_test_clf.shape[0]:,} samples\")\n",
    "print(f\"   ‚Ä¢ Claim rate in train: {y_train_clf.mean()*100:.3f}%\")\n",
    "print(f\"   ‚Ä¢ Claim rate in test: {y_test_clf.mean()*100:.3f}%\")\n",
    "\n",
    "print(f\"\\nüìà REGRESSION DATA SPLIT (1,542 claims):\")\n",
    "print(f\"   ‚Ä¢ Training: {X_train_reg.shape[0]:,} claims\")\n",
    "print(f\"   ‚Ä¢ Testing: {X_test_reg.shape[0]:,} claims\")\n",
    "print(f\"   ‚Ä¢ Average claim (train): R {y_train_reg.mean():,.2f}\")\n",
    "print(f\"   ‚Ä¢ Average claim (test): R {y_test_reg.mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: FIXED - CLASSIFICATION MODELS WITH MEMORY OPTIMIZATION\n",
    "print(\"ü§ñ MODEL 1: CLASSIFICATION - WITH MEMORY OPTIMIZATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä Dataset: 100,000 policies with {y_classification.sum():,} claims ({y_classification.mean()*100:.3f}% claim rate)\")\n",
    "print(\"‚ö†Ô∏è  Using sampling to avoid memory issues...\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "# OPTION 1: Use smaller sample for model comparison (100K)\n",
    "print(\"\\nüìâ Using 100K sample for model comparison (to avoid memory issues)...\")\n",
    "sample_size = 100000\n",
    "sample_indices = np.random.choice(len(X_train_clf), sample_size, replace=True)\n",
    "\n",
    "X_train_sample = X_train_clf.iloc[sample_indices]\n",
    "y_train_sample = y_train_clf.iloc[sample_indices]\n",
    "\n",
    "print(f\"   ‚Ä¢ Training sample: {len(X_train_sample):,} policies\")\n",
    "print(f\"   ‚Ä¢ Claims in sample: {y_train_sample.sum():,} ({y_train_sample.mean()*100:.3f}%)\")\n",
    "\n",
    "# OPTION 2: Reduce cardinality of high-cardinality features\n",
    "print(\"\\nüîç Checking feature cardinality...\")\n",
    "high_card_features = []\n",
    "for feature in categorical_features:\n",
    "    unique_vals = df[feature].nunique()\n",
    "    if unique_vals > 20:\n",
    "        high_card_features.append(feature)\n",
    "        print(f\"   ‚ö†Ô∏è {feature}: {unique_vals} unique values (high cardinality)\")\n",
    "\n",
    "# Create SIMPLER preprocessing for model comparison\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "simple_categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))  # Much more memory efficient\n",
    "])\n",
    "\n",
    "simple_preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', simple_categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Models with simpler preprocessing\n",
    "models_clf = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('preprocessor', simple_preprocessor),\n",
    "        ('classifier', LogisticRegression(\n",
    "            random_state=42, \n",
    "            max_iter=1000,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('preprocessor', simple_preprocessor),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            random_state=42, \n",
    "            n_estimators=50,  # Reduced for speed\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            max_depth=10  # Limit depth to prevent overfitting\n",
    "        ))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('preprocessor', simple_preprocessor),\n",
    "        ('classifier', xgb.XGBClassifier(\n",
    "            random_state=42, \n",
    "            n_estimators=50,  # Reduced for speed\n",
    "            scale_pos_weight=len(y_train_sample[y_train_sample==0]) / len(y_train_sample[y_train_sample==1]),\n",
    "            use_label_encoder=False, \n",
    "            eval_metric='logloss',\n",
    "            n_jobs=-1,\n",
    "            max_depth=6\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "print(\"\\nüèãÔ∏è TRAINING MODELS ON 100K SAMPLE...\")\n",
    "results_clf = {}\n",
    "predictions = {}\n",
    "\n",
    "for name, model in models_clf.items():\n",
    "    print(f\"\\nüìä {name}:\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_sample, y_train_sample)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predict on TEST set (full 100K test)\n",
    "    y_pred = model.predict(X_test_clf)\n",
    "    y_pred_proba = model.predict_proba(X_test_clf)[:, 1]\n",
    "    \n",
    "    predictions[name] = {'y_pred': y_pred, 'y_pred_proba': y_pred_proba}\n",
    "    \n",
    "    results_clf[name] = {\n",
    "        'accuracy': accuracy_score(y_test_clf, y_pred),\n",
    "        'precision': precision_score(y_test_clf, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test_clf, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_test_clf, y_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(y_test_clf, y_pred_proba),\n",
    "        'training_time_sec': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úì Training time: {training_time:.1f} seconds\")\n",
    "    print(f\"   ‚úì Accuracy: {results_clf[name]['accuracy']:.4f}\")\n",
    "    print(f\"   ‚úì Precision: {results_clf[name]['precision']:.4f}\")\n",
    "    print(f\"   ‚úì Recall: {results_clf[name]['recall']:.4f}\")\n",
    "    print(f\"   ‚úì F1-Score: {results_clf[name]['f1']:.4f}\")\n",
    "    print(f\"   ‚úì ROC-AUC: {results_clf[name]['roc_auc']:.4f}\")\n",
    "\n",
    "# Create comparison\n",
    "results_df_clf = pd.DataFrame(results_clf).T\n",
    "print(\"\\nüèÜ CLASSIFICATION MODEL COMPARISON:\")\n",
    "print(results_df_clf.round(4).sort_values('recall', ascending=False))\n",
    "\n",
    "# Best model\n",
    "best_model_name = results_df_clf['recall'].idxmax()\n",
    "print(f\"\\nüéØ BEST MODEL FOR DETECTING CLAIMS: {best_model_name}\")\n",
    "print(f\"   Recall: {results_df_clf.loc[best_model_name, 'recall']:.4f}\")\n",
    "print(f\"   F1-Score: {results_df_clf.loc[best_model_name, 'f1']:.4f}\")\n",
    "print(f\"   ROC-AUC: {results_df_clf.loc[best_model_name, 'roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb84eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: DETAILED ANALYSIS OF LOGISTIC REGRESSION\n",
    "print(\"üîç DETAILED ANALYSIS: LOGISTIC REGRESSION (Best for Claim Detection)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get the trained Logistic Regression model\n",
    "lr_model = models_clf['Logistic Regression']\n",
    "y_pred_lr = predictions['Logistic Regression']['y_pred']\n",
    "y_pred_proba_lr = predictions['Logistic Regression']['y_pred_proba']\n",
    "\n",
    "# 1. Classification Report\n",
    "print(\"\\nüìã CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test_clf, y_pred_lr, \n",
    "                          target_names=['No Claim (0)', 'Claim (1)'],\n",
    "                          digits=4))\n",
    "\n",
    "# 2. Confusion Matrix (with business interpretation)\n",
    "cm = confusion_matrix(y_test_clf, y_pred_lr)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\nüî¢ CONFUSION MATRIX:\")\n",
    "print(f\"                    Predicted NO Claim   Predicted Claim\")\n",
    "print(f\"Actual NO Claim   |     {tn:>8} (TN)    |    {fp:>8} (FP)   |\")\n",
    "print(f\"Actual Claim      |     {fn:>8} (FN)    |    {tp:>8} (TP)   |\")\n",
    "\n",
    "print(f\"\\nüíº BUSINESS INTERPRETATION:\")\n",
    "print(f\"   ‚Ä¢ True Positives (Correct Claims): {tp:,} policies correctly identified as claims\")\n",
    "print(f\"   ‚Ä¢ False Negatives (MISSED Claims): {fn:,} claims we FAILED to detect (MOST COSTLY ERROR!)\")\n",
    "print(f\"   ‚Ä¢ False Positives (False Alarms): {fp:,} policies flagged as claims but no claim\")\n",
    "print(f\"   ‚Ä¢ True Negatives (Correct No Claims): {tn:,} policies correctly identified as no claim\")\n",
    "\n",
    "# Calculate business metrics\n",
    "total_actual_claims = tp + fn\n",
    "total_predicted_claims = tp + fp\n",
    "\n",
    "print(f\"\\nüìä CLAIM DETECTION METRICS:\")\n",
    "print(f\"   ‚Ä¢ Claim Detection Rate (Recall): {tp/total_actual_claims:.2%}\")\n",
    "print(f\"   ‚Ä¢ False Alarm Rate: {fp/(fp+tn):.4%}\")\n",
    "print(f\"   ‚Ä¢ Precision: Only {tp/total_predicted_claims:.2%} of flagged policies actually have claims\")\n",
    "\n",
    "# 3. ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_clf, y_pred_proba_lr)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: ROC Curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('ROC Curve - Logistic Regression\\n(Detecting Rare Claims: 0.308% of data)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test_clf, y_pred_proba_lr)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='green', lw=2)\n",
    "plt.xlabel('Recall (Claim Detection Rate)')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve\\nTrade-off: Higher Recall = Lower Precision')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéØ KEY INSIGHT: We're detecting {tp/total_actual_claims:.1%} of claims,\")\n",
    "print(f\"   but {fp/(fp+tn):.2%} of safe policies are falsely flagged as risky.\")\n",
    "print(f\"   This trade-off might be acceptable to avoid missing claims.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2 - REGRESSION (Predict Claim Amount)\n",
    "print(\"ü§ñ MODEL 2: REGRESSION - PREDICTING CLAIM AMOUNT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä Training on {len(X_train_reg):,} claims, testing on {len(X_test_reg):,} claims\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Create simpler preprocessing for regression (same as before)\n",
    "reg_preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', simple_categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Regression models\n",
    "models_reg = {\n",
    "    'Linear Regression': Pipeline([\n",
    "        ('preprocessor', reg_preprocessor),\n",
    "        ('regressor', LinearRegression())\n",
    "    ]),\n",
    "    'Random Forest Regressor': Pipeline([\n",
    "        ('preprocessor', reg_preprocessor),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            random_state=42,\n",
    "            n_estimators=50,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    'XGBoost Regressor': Pipeline([\n",
    "        ('preprocessor', reg_preprocessor),\n",
    "        ('regressor', xgb.XGBRegressor(\n",
    "            random_state=42,\n",
    "            n_estimators=50,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "print(\"\\nüèãÔ∏è TRAINING REGRESSION MODELS...\")\n",
    "results_reg = {}\n",
    "predictions_reg = {}\n",
    "\n",
    "for name, model in models_reg.items():\n",
    "    print(f\"\\nüìä {name}:\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_reg, y_train_reg)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_reg)\n",
    "    \n",
    "    # Store\n",
    "    predictions_reg[name] = y_pred\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred))\n",
    "    mae = mean_absolute_error(y_test_reg, y_pred)\n",
    "    r2 = r2_score(y_test_reg, y_pred)\n",
    "    \n",
    "    results_reg[name] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'training_time_sec': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úì Training time: {training_time:.1f} seconds\")\n",
    "    print(f\"   ‚úì RMSE: R {rmse:,.2f}\")\n",
    "    print(f\"   ‚úì MAE: R {mae:,.2f}\")\n",
    "    print(f\"   ‚úì R¬≤ Score: {r2:.4f}\")\n",
    "    \n",
    "    # Compare to average\n",
    "    avg_claim = y_test_reg.mean()\n",
    "    print(f\"   ‚úì Avg claim: R {avg_claim:,.2f} (RMSE is {rmse/avg_claim*100:.1f}% of avg)\")\n",
    "\n",
    "# Create comparison\n",
    "results_df_reg = pd.DataFrame(results_reg).T\n",
    "print(\"\\nüèÜ REGRESSION MODEL COMPARISON:\")\n",
    "print(results_df_reg.round(4).sort_values('R2', ascending=False))\n",
    "\n",
    "# Best regression model\n",
    "best_reg_name = results_df_reg['R2'].idxmax()\n",
    "print(f\"\\nüéØ BEST REGRESSION MODEL: {best_reg_name}\")\n",
    "print(f\"   R¬≤ Score: {results_df_reg.loc[best_reg_name, 'R2']:.4f}\")\n",
    "print(f\"   RMSE: R {results_df_reg.loc[best_reg_name, 'RMSE']:,.2f}\")\n",
    "\n",
    "# Visualize predictions\n",
    "print(f\"\\nüìà VISUALIZING {best_reg_name} PREDICTIONS...\")\n",
    "y_pred_best = predictions_reg[best_reg_name]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Actual vs Predicted\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test_reg, y_pred_best, alpha=0.6, s=20)\n",
    "plt.plot([y_test_reg.min(), y_test_reg.max()], \n",
    "         [y_test_reg.min(), y_test_reg.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Claim Amount (R)')\n",
    "plt.ylabel('Predicted Claim Amount (R)')\n",
    "plt.title(f'{best_reg_name}: Actual vs Predicted\\nR¬≤ = {results_df_reg.loc[best_reg_name, \"R2\"]:.3f}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "residuals = y_test_reg - y_pred_best\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.6, s=20)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicted Claim Amount (R)')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title('Residual Plot\\n(Check for patterns = bad model)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e075ad",
   "metadata": {},
   "source": [
    "## COMBINE MODELS & CREATE RISK SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE MODELS FOR RISK-BASED SCORING\n",
    "print(\"üéØ STEP 10: CREATING RISK-BASED SCORING SYSTEM\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüí° STRATEGY: Combine Classification + Regression for better insights\")\n",
    "print(\"   Risk Score = Probability of Claim √ó Expected Claim Amount\")\n",
    "\n",
    "# Train FINAL models on FULL data (for production use)\n",
    "print(\"\\nüèãÔ∏è TRAINING FINAL MODELS ON FULL DATA...\")\n",
    "\n",
    "# 1. Final Classification Model (use best: Logistic Regression)\n",
    "print(\"üìä Training final Logistic Regression on 100K samples...\")\n",
    "final_clf_model = Pipeline([\n",
    "    ('preprocessor', simple_preprocessor),\n",
    "    ('classifier', LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "final_clf_model.fit(X_train_clf, y_train_clf)\n",
    "clf_time = time.time() - start_time\n",
    "print(f\"   ‚úì Training time: {clf_time:.1f} seconds\")\n",
    "\n",
    "# 2. Final Regression Model (use best: Linear Regression)\n",
    "print(\"üìä Training final Linear Regression on 1,233 claims...\")\n",
    "final_reg_model = Pipeline([\n",
    "    ('preprocessor', reg_preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "final_reg_model.fit(X_train_reg, y_train_reg)\n",
    "reg_time = time.time() - start_time\n",
    "print(f\"   ‚úì Training time: {reg_time:.1f} seconds\")\n",
    "\n",
    "# 3. Create Risk Scores for test data\n",
    "print(\"\\nüîÆ CREATING RISK SCORES...\")\n",
    "\n",
    "# Get probability of claim for ALL test policies\n",
    "claim_probabilities = final_clf_model.predict_proba(X_test_clf)[:, 1]\n",
    "\n",
    "# Get predicted claim amount (for those predicted to have claims)\n",
    "# Note: We predict amount for ALL, but will use wisely\n",
    "predicted_amounts = final_reg_model.predict(X_test_clf)\n",
    "\n",
    "# Create risk score (0 to 100)\n",
    "risk_scores = claim_probabilities * (predicted_amounts / 1000)  # Scale down for readability\n",
    "risk_scores = (risk_scores / risk_scores.max() * 100).clip(0, 100)  # Scale to 0-100\n",
    "\n",
    "# Add to test data for analysis\n",
    "test_with_risk = X_test_clf.copy()\n",
    "test_with_risk['Claim_Probability'] = claim_probabilities\n",
    "test_with_risk['Predicted_Claim_Amount'] = predicted_amounts\n",
    "test_with_risk['Risk_Score'] = risk_scores\n",
    "test_with_risk['Actual_TotalClaims'] = y_test_clf.values\n",
    "test_with_risk['Actual_Claim_Amount'] = df.loc[y_test_clf.index, 'TotalClaims'].values\n",
    "\n",
    "print(f\"\\nüìä RISK SCORE DISTRIBUTION:\")\n",
    "print(f\"   ‚Ä¢ Min Risk Score: {risk_scores.min():.2f}\")\n",
    "print(f\"   ‚Ä¢ Max Risk Score: {risk_scores.max():.2f}\")\n",
    "print(f\"   ‚Ä¢ Mean Risk Score: {risk_scores.mean():.2f}\")\n",
    "print(f\"   ‚Ä¢ Median Risk Score: {np.median(risk_scores):.2f}\")\n",
    "\n",
    "# Analyze by risk segments\n",
    "print(\"\\nüéØ RISK SEGMENT ANALYSIS:\")\n",
    "risk_segments = pd.cut(risk_scores, bins=[0, 20, 40, 60, 80, 100], \n",
    "                      labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "segment_stats = pd.DataFrame({\n",
    "    'Segment': risk_segments,\n",
    "    'Claim_Probability': claim_probabilities,\n",
    "    'Actual_Claim': y_test_clf.values\n",
    "}).groupby('Segment').agg(\n",
    "    Count=('Actual_Claim', 'count'),\n",
    "    Avg_Risk_Score=('Claim_Probability', lambda x: (x * 100).mean()),\n",
    "    Actual_Claim_Rate=('Actual_Claim', 'mean'),\n",
    "    Actual_Claims=('Actual_Claim', 'sum')\n",
    ").round(4)\n",
    "\n",
    "print(segment_stats)\n",
    "\n",
    "# Visualize risk segmentation\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Risk Score Distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(risk_scores, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Risk Score (0-100)')\n",
    "plt.ylabel('Number of Policies')\n",
    "plt.title('Distribution of Risk Scores\\n(Lower = Safer, Higher = Riskier)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Actual Claim Rate by Risk Segment\n",
    "plt.subplot(1, 2, 2)\n",
    "segments = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "claim_rates = segment_stats['Actual_Claim_Rate'].values * 100  # Convert to percentage\n",
    "\n",
    "plt.bar(segments, claim_rates, color=['green', 'lightgreen', 'yellow', 'orange', 'red'])\n",
    "plt.xlabel('Risk Segment')\n",
    "plt.ylabel('Actual Claim Rate (%)')\n",
    "plt.title('Actual Claim Rate by Risk Segment\\n(Validating our model)')\n",
    "plt.xticks(rotation=45)\n",
    "for i, v in enumerate(claim_rates):\n",
    "    plt.text(i, v + 0.01, f'{v:.2f}%', ha='center', va='bottom')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ KEY INSIGHT: Higher risk scores correlate with higher actual claim rates!\")\n",
    "print(f\"   This validates our risk scoring approach.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58846d4",
   "metadata": {},
   "source": [
    "## Shap\n",
    "- Understanding SHAP in Machine Learning\n",
    "SHAP (SHapley Additive exPlanations) is a powerful framework for interpreting machine learning models. It is based on cooperative game theory and provides a consistent way to explain how individual features contribute to a model's predictions. SHAP is particularly useful for understanding complex, black-box models like neural networks, gradient boosting, and random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d51c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SHAP ANALYSIS - UNDERSTANDING WHAT DRIVES RISK\n",
    "print(\"üîç STEP 11: SHAP ANALYSIS - BUSINESS INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüí° Understanding which features drive claim probability\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    print(\"‚úÖ SHAP library available, generating insights...\")\n",
    "    \n",
    "    # Prepare data for SHAP (use sample for speed)\n",
    "    sample_size = 5000\n",
    "    sample_idx = np.random.choice(len(X_test_clf), min(sample_size, len(X_test_clf)), replace=False)\n",
    "    X_sample = X_test_clf.iloc[sample_idx]\n",
    "    \n",
    "    # Get the preprocessed data\n",
    "    preprocessed_data = final_clf_model.named_steps['preprocessor'].transform(X_sample)\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    # For categorical features with ordinal encoding\n",
    "    feature_names = numerical_features.copy()\n",
    "    for cat_feat in categorical_features:\n",
    "        feature_names.append(cat_feat)\n",
    "    \n",
    "    # Get the classifier\n",
    "    classifier = final_clf_model.named_steps['classifier']\n",
    "    \n",
    "    # Create SHAP explainer\n",
    "    explainer = shap.LinearExplainer(classifier, preprocessed_data)\n",
    "    shap_values = explainer.shap_values(preprocessed_data)\n",
    "    \n",
    "    print(f\"\\nüìä Analyzing {len(X_sample)} policies for feature importance...\")\n",
    "    \n",
    "    # Summary plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    shap.summary_plot(shap_values, preprocessed_data, feature_names=feature_names, \n",
    "                     max_display=15, show=False)\n",
    "    plt.title(\"Top Features Driving Claim Probability\\n(Positive = Increases Risk, Negative = Decreases Risk)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Get mean absolute SHAP values for top features\n",
    "    shap_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': np.abs(shap_values).mean(0)\n",
    "    }).sort_values('importance', ascending=False).head(10)\n",
    "    \n",
    "    print(\"\\nüèÜ TOP 10 FEATURES AFFECTING CLAIM PROBABILITY:\")\n",
    "    for i, row in shap_df.iterrows():\n",
    "        print(f\"   {i+1:2d}. {row['feature']:20s} | Impact: {row['importance']:.4f}\")\n",
    "    \n",
    "    print(\"\\nüíº BUSINESS INTERPRETATION:\")\n",
    "    print(\"1. Features with POSITIVE SHAP: Increase claim probability\")\n",
    "    print(\"2. Features with NEGATIVE SHAP: Decrease claim probability\")\n",
    "    print(\"3. Larger absolute values = stronger influence\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è SHAP not installed. Installing now...\")\n",
    "    !pip install shap -q\n",
    "    import shap\n",
    "    print(\"‚úÖ SHAP installed. Please re-run this cell.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è SHAP analysis failed: {e}\")\n",
    "    print(\"\\nüìä ALTERNATIVE: Feature Importance from Logistic Regression\")\n",
    "    \n",
    "    # Get coefficients from logistic regression\n",
    "    coefs = final_clf_model.named_steps['classifier'].coef_[0]\n",
    "    \n",
    "    # Map to feature names (simplified)\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names[:len(coefs)],\n",
    "        'coefficient': coefs,\n",
    "        'abs_importance': np.abs(coefs)\n",
    "    }).sort_values('abs_importance', ascending=False).head(15)\n",
    "    \n",
    "    print(\"\\nüèÜ TOP FEATURES FROM LOGISTIC REGRESSION:\")\n",
    "    for i, row in importance_df.iterrows():\n",
    "        effect = \"INCREASES\" if row['coefficient'] > 0 else \"DECREASES\"\n",
    "        print(f\"   ‚Ä¢ {row['feature']:20s}: {effect} risk (coef: {row['coefficient']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ea4d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models saved successfully!\n",
      "üìÅ Location:\n",
      "   ‚Ä¢ models/final_claim_classifier.joblib\n",
      "   ‚Ä¢ models/final_claim_regressor.joblib\n"
     ]
    }
   ],
   "source": [
    "# SAVE TRAINED MODELS TO models/ FOLDER\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Save classification model\n",
    "joblib.dump(final_clf_model, \"../models/final_claim_classifier_model.joblib\")\n",
    "\n",
    "# Save regression model\n",
    "joblib.dump(final_reg_model, \"../models/final_claim_regressor_model.joblib\")\n",
    "\n",
    "print(\"‚úÖ Models saved successfully!\")\n",
    "print(\"üìÅ Location:\")\n",
    "print(\"   ‚Ä¢ models/final_claim_classifier.joblib\")\n",
    "print(\"   ‚Ä¢ models/final_claim_regressor.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  BUSINESS RECOMMENDATIONS & PREMIUM OPTIMIZATION\n",
    "print(\"üí∞ STEP 12: BUSINESS RECOMMENDATIONS & PREMIUM OPTIMIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìà KEY FINDINGS FROM OUR ANALYSIS:\")\n",
    "print(\"1. Claim Detection: Logistic Regression detects 80.84% of claims\")\n",
    "print(\"2. False Positives: 21.69% of safe policies flagged as risky (trade-off)\")\n",
    "print(\"3. Amount Prediction: Linear Regression explains only 30% of claim amounts\")\n",
    "print(\"4. Risk Scoring: Higher risk scores correlate with higher actual claim rates\")\n",
    "\n",
    "print(\"\\nüéØ RECOMMENDED STRATEGY FOR ACIS:\")\n",
    "print(\"   TWO-TIER PRICING APPROACH:\")\n",
    "\n",
    "# Calculate suggested premium adjustments\n",
    "print(\"\\nüí° PREMIUM ADJUSTMENT SUGGESTIONS:\")\n",
    "\n",
    "# Get current average premium\n",
    "if 'AnnualPremium' in df.columns:\n",
    "    avg_premium = df['AnnualPremium'].mean()\n",
    "    print(f\"   ‚Ä¢ Current average premium: R {avg_premium:,.2f}\")\n",
    "else:\n",
    "    avg_premium = df['CalculatedPremiumPerTerm'].mean() * 12  # Annualize if monthly\n",
    "    print(f\"   ‚Ä¢ Current average premium (annualized): R {avg_premium:,.2f}\")\n",
    "\n",
    "# Suggested adjustments by risk segment\n",
    "print(\"\\nüìä SUGGESTED PREMIUM ADJUSTMENTS BY RISK SEGMENT:\")\n",
    "\n",
    "# Based on actual claim rates in each segment\n",
    "premium_adjustments = {\n",
    "    'Very Low': -15,   # Discount for very safe customers\n",
    "    'Low': -5,        # Small discount\n",
    "    'Medium': 0,      # Keep current premium\n",
    "    'High': +10,      # Moderate increase\n",
    "    'Very High': +25  # Significant increase\n",
    "}\n",
    "\n",
    "for segment, adjustment in premium_adjustments.items():\n",
    "    if segment in segment_stats.index:\n",
    "        claim_rate = segment_stats.loc[segment, 'Actual_Claim_Rate'] * 100\n",
    "        new_premium = avg_premium * (1 + adjustment/100)\n",
    "        print(f\"   ‚Ä¢ {segment:10s}: {adjustment:>+3d}% adjustment\")\n",
    "        print(f\"     Claim rate: {claim_rate:.2f}% | New premium: R {new_premium:,.2f}\")\n",
    "\n",
    "print(\"\\nüéØ MARKETING STRATEGY SUGGESTIONS:\")\n",
    "print(\"1. TARGET 'Very Low' & 'Low' risk segments:\")\n",
    "print(\"   ‚Ä¢ Offer 5-15% premium discounts\")\n",
    "print(\"   ‚Ä¢ Focus marketing campaigns on these segments\")\n",
    "print(\"   ‚Ä¢ Customer retention: Reward low-risk customers\")\n",
    "\n",
    "print(\"\\n2. MANAGE 'High' & 'Very High' risk segments:\")\n",
    "print(\"   ‚Ä¢ Apply risk-adjusted premiums (+10% to +25%)\")\n",
    "print(\"   ‚Ä¢ Consider additional risk mitigation:\")\n",
    "print(\"     - Higher excess (deductible)\")\n",
    "print(\"     - Stricter coverage limits\")\n",
    "print(\"     - Telematics/driving behavior monitoring\")\n",
    "\n",
    "print(\"\\n3. FEATURES TO FOCUS ON (from SHAP analysis):\")\n",
    "print(\"   ‚Ä¢ Location factors (Province, Postal Code)\")\n",
    "print(\"   ‚Ä¢ Vehicle characteristics (Type, Make, Age)\")\n",
    "print(\"   ‚Ä¢ Coverage details (Sum Insured, Excess)\")\n",
    "\n",
    "print(\"\\nüìà EXPECTED BUSINESS IMPACT:\")\n",
    "print(\"   ‚Ä¢ Better risk segmentation ‚Üí More accurate pricing\")\n",
    "print(\"   ‚Ä¢ Attract low-risk customers with discounts\")\n",
    "print(\"   ‚Ä¢ Price high-risk customers appropriately\")\n",
    "print(\"   ‚Ä¢ Overall portfolio profitability improvement\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
